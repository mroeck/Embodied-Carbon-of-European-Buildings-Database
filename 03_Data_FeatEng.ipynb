{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data feature engineering script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: [Andreas Sørensen](https://www.linkedin.com/in/a-soerensen) and [Martin Röck](https://www.linkedin.com/in/martinroeck/) - Source: https://doi.org/10.5281/zenodo.5895051"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T21:33:56.749346Z",
     "start_time": "2021-06-05T21:33:54.444930Z"
    }
   },
   "outputs": [],
   "source": [
    "# SETUP\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T21:33:56.765305Z",
     "start_time": "2021-06-05T21:33:56.751341Z"
    }
   },
   "outputs": [],
   "source": [
    "# set data frame printing to unlimited rows and columns\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #gets rid of the 'red' warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature engineering data for analysis...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import and tidy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import data from \"Data_Concat\" csv to pandas dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T21:33:56.812177Z",
     "start_time": "2021-06-05T21:33:56.767298Z"
    }
   },
   "outputs": [],
   "source": [
    "# IMPORT DATA FROM DATA:CONCAT CSV-FILE\n",
    "\n",
    "filename = 'EU-ECB_dataset_concatenated.csv'\n",
    "df = pd.read_csv('00_data/2_data_concatenated/'+filename, delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rename Ökobau to Oekobau.dat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace entries with English translation\n",
    "df.lca_database.replace('Ökobau','Oekobau.dat',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Harmonize 'no data' to 'No data'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('no data','No data',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exclude renovation cases from dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.bldg_project_status != 'Renovation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean 'bldg_year_complete' use '.' as decimal instead of ','**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[pd.notna(df['bldg_year_complete']), 'bldg_year_complete'] = df['bldg_year_complete'].str.replace(',', '.').astype(float)\n",
    "#df['bldg_year_complete'] = df['bldg_year_complete'].str.replace(',', '.').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the entries are formated correctly\n",
    "#df['bldg_year_complete'].unique()\n",
    "#df['bldg_year_complete'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change 'bldg_year_permit' and 'bldg_year_complete' dtype to integer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBS: THIS DOES NOT WORK YET - STILL CREATES FLOATS WHEN GOING FROM 0 to NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df['bldg_year_permit'] = df['bldg_year_permit'].fillna(0).astype(int)\\ndf.loc[(df['bldg_year_permit'] == 0), 'bldg_year_permit'] = np.nan\\n\\ndf['bldg_year_complete'] = df['bldg_year_complete'].fillna(0).astype(int)\\ndf.loc[(df['bldg_year_complete'] == 0), 'bldg_year_complete'] = np.nan\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"df['bldg_year_permit'] = df['bldg_year_permit'].fillna(0).astype(int)\n",
    "df.loc[(df['bldg_year_permit'] == 0), 'bldg_year_permit'] = np.nan\n",
    "\n",
    "df['bldg_year_complete'] = df['bldg_year_complete'].fillna(0).astype(int)\n",
    "df.loc[(df['bldg_year_complete'] == 0), 'bldg_year_complete'] = np.nan\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df['bldg_year_permit'].dtypes)\n",
    "#print(df['bldg_year_complete'].dtypes)\n",
    "\n",
    "#print(df['bldg_year_permit'].unique())\n",
    "#print(df['bldg_year_complete'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df['bldg_year_permit'].dtypes)\n",
    "#print(df['bldg_year_complete'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adjust 0 to NaN in all columns (except 'bldg_floors_bg') before feature engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'bldg_floors_bg' is allowed to have 0, the rest are changed to NaN\n",
    "\n",
    "#Create list of columns without 'bldg_floors_bg'\n",
    "col_list = list(df.drop('bldg_floors_bg',axis=1).columns)\n",
    "\n",
    "#Loop over list of columns and replace 0 with NaN\n",
    "for col in col_list:\n",
    "    df[col].replace(to_replace=[0,\"0\"], value=np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Add admin features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Add features (data columns) based on existing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T21:33:56.843097Z",
     "start_time": "2021-06-05T21:33:56.814172Z"
    }
   },
   "outputs": [],
   "source": [
    "#Add site_country_code for each country\n",
    "df.loc[(df['site_country'] == 'Denmark'), 'site_country_code'] = 'DK'\n",
    "df.loc[(df['site_country'] == 'France'), 'site_country_code'] = 'FR'\n",
    "df.loc[(df['site_country'] == 'Austria'), 'site_country_code'] = 'AT'\n",
    "df.loc[(df['site_country'] == 'Germany'), 'site_country_code'] = 'DE'\n",
    "df.loc[(df['site_country'] == 'Switzerland'), 'site_country_code'] = 'CH'\n",
    "df.loc[(df['site_country'] == 'United Kingdom'), 'site_country_code'] = 'UK'\n",
    "df.loc[(df['site_country'] == 'Italy'), 'site_country_code'] = 'IT'\n",
    "df.loc[(df['site_country'] == 'Portugal'), 'site_country_code'] = 'PT'\n",
    "df.loc[(df['site_country'] == 'Ireland'), 'site_country_code'] = 'IE'\n",
    "df.loc[(df['site_country'] == 'Greece'), 'site_country_code'] = 'GR'\n",
    "df.loc[(df['site_country'] == 'Norway'), 'site_country_code'] = 'NR'\n",
    "df.loc[(df['site_country'] == 'Belgium'), 'site_country_code'] = 'BE'\n",
    "df.loc[(df['site_country'] == 'Lithuania'), 'site_country_code'] = 'LT'\n",
    "df.loc[(df['site_country'] == 'Spain'), 'site_country_code'] = 'ES'\n",
    "df.loc[(df['site_country'] == 'Finland'), 'site_country_code'] = 'FI'\n",
    "df.loc[(df['site_country'] == 'Netherlands'), 'site_country_code'] = 'NL'\n",
    "df.loc[(df['site_country'] == 'Poland'), 'site_country_code'] = 'PL'\n",
    "df.loc[(df['site_country'] == 'Sweden'), 'site_country_code'] = 'SE'\n",
    "df.loc[(df['site_country'] == 'Lithuania'), 'site_country_code'] = 'LT'\n",
    "\n",
    "#Add site_country_code for Europe (CLF data)\n",
    "df.loc[(df['site_country'] == 'Europe'), 'site_country_code'] = 'EU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T21:33:56.858055Z",
     "start_time": "2021-06-05T21:33:56.845090Z"
    }
   },
   "outputs": [],
   "source": [
    "#Add admin_data_partner\n",
    "df['admin_data_partner'] = df['admin_project_contact']\n",
    "\n",
    "#Adjust PORR data for admin_project_contact\n",
    "df.loc[(df['admin_project_contact'] == 'Neururer' ), 'admin_data_partner'] = 'PORR'\n",
    "df.loc[(df['admin_project_contact'] == 'Wald'), 'admin_data_partner'] = 'PORR'\n",
    "df.loc[(df['admin_project_contact'] == 'Auinger' ), 'admin_data_partner'] = 'PORR'\n",
    "df.loc[(df['admin_project_contact'] == 'Holdefleiss'), 'admin_data_partner'] = 'PORR'\n",
    "df.loc[(df['admin_project_contact'] == 'Ruhe'), 'admin_data_partner'] = 'PORR'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. GHG feature fill [kgCO2] => [kgCO2/m2/year]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add missing GHG [kgCO2/m2/year] features based on GHG [kgCO2], bldg_area_gfa and lca_RSP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1 Individual modules [kgCO2] => individual modules [kgCO2e/m2/a]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T21:33:56.936844Z",
     "start_time": "2021-06-05T21:33:56.860050Z"
    }
   },
   "outputs": [],
   "source": [
    "#Add/fill feature:\n",
    "\"\"\"\n",
    "\"Results - Individual modules [kgCO2e/m2/a]\"\n",
    "\"\"\"\n",
    "#based on feature(s):\n",
    "\"\"\"\n",
    "\"Results - Individual modules [kgCO2e]\", \"bldg_area_gfa\" and \"lca_RSP\"\n",
    "\"\"\"\n",
    "#This is done by checking that the wanted feature is NaN to avoid overwriting existing data,\n",
    "#if is NaN, it is checked whether the necessary values to fill it are not NaN,\n",
    "#if these are not NaN, they are used to calculate results in [kgCO2e/m2/a].\n",
    "#If wanted feature is already present or necessary values are NaN, the row is skipped.\n",
    "\n",
    "#A1\n",
    "df.loc[pd.isnull(df['GHG_A1_m2a']) & pd.notna(df['GHG_A1']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']),'GHG_A1_m2a'] = df['GHG_A1']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#A2\n",
    "df.loc[pd.isnull(df['GHG_A2_m2a']) & pd.notna(df['GHG_A2']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_A2_m2a'] = df['GHG_A2']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#A3\n",
    "df.loc[pd.isnull(df['GHG_A3_m2a']) & pd.notna(df['GHG_A3']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_A3_m2a'] = df['GHG_A3']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#A4\n",
    "df.loc[pd.isnull(df['GHG_A4_m2a']) & pd.notna(df['GHG_A4']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_A4_m2a'] = df['GHG_A4']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#A5\n",
    "df.loc[pd.isnull(df['GHG_A5_m2a']) & pd.notna(df['GHG_A5']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_A5_m2a'] = df['GHG_A5']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#B1\n",
    "df.loc[pd.isnull(df['GHG_B1_m2a']) & pd.notna(df['GHG_B1']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_B1_m2a'] = df['GHG_B1']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#B2\n",
    "df.loc[pd.isnull(df['GHG_B2_m2a']) & pd.notna(df['GHG_B2']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_B2_m2a'] = df['GHG_B2']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#B3\n",
    "df.loc[pd.isnull(df['GHG_B3_m2a']) & pd.notna(df['GHG_B3']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_B3_m2a'] = df['GHG_B3']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#B4\n",
    "df.loc[pd.isnull(df['GHG_B4_m2a']) & pd.notna(df['GHG_B4']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_B4_m2a'] = df['GHG_B4']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#B5\n",
    "df.loc[pd.isnull(df['GHG_B5_m2a']) & pd.notna(df['GHG_B5']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_B5_m2a'] = df['GHG_B5']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#B6\n",
    "df.loc[pd.isnull(df['GHG_B6_m2a']) & pd.notna(df['GHG_B6']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_B6_m2a'] = df['GHG_B6']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#B7\n",
    "df.loc[pd.isnull(df['GHG_B7_m2a']) & pd.notna(df['GHG_B7']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_B7_m2a'] = df['GHG_B7']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#C1\n",
    "df.loc[pd.isnull(df['GHG_C1_m2a']) & pd.notna(df['GHG_C1']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_C1_m2a'] = df['GHG_C1']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#C2\n",
    "df.loc[pd.isnull(df['GHG_C2_m2a']) & pd.notna(df['GHG_C2']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_C2_m2a'] = df['GHG_C2']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#C3\n",
    "df.loc[pd.isnull(df['GHG_C3_m2a']) & pd.notna(df['GHG_C3']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_C3_m2a'] = df['GHG_C3']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#C4\n",
    "df.loc[pd.isnull(df['GHG_C4_m2a']) & pd.notna(df['GHG_C4']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_C4_m2a'] = df['GHG_C4']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#D\n",
    "df.loc[pd.isnull(df['GHG_D_m2a']) & pd.notna(df['GHG_D']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_D_m2a'] = df['GHG_D']/df['bldg_area_gfa']/df['lca_RSP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 Aggregated modules [kgCO2] => aggregated modules [kgCO2e/m2/a]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T21:33:56.982757Z",
     "start_time": "2021-06-05T21:33:56.938839Z"
    }
   },
   "outputs": [],
   "source": [
    "#Add/fill feature:\n",
    "\"\"\"\n",
    "\"Results - Aggregated modules [kgCO2e/m2/a]\"\n",
    "\"\"\"\n",
    "#based on feature(s):\n",
    "\"\"\"\n",
    "\"Results - Aggregated modules [kgCO2e]\", \"bldg_area_gfa\" and \"lca_RSP\"\n",
    "\"\"\"\n",
    "#This is done by checking that the wanted feature is NaN to avoid overwriting existing data,\n",
    "#if is NaN, it is checked whether the necessary values to fill it are not NaN,\n",
    "#if these are not NaN, they are used to calculate results in [kgCO2e/m2/a].\n",
    "#If wanted feature is already present or necessary values are NaN, the row is skipped.\n",
    "\n",
    "#A1-A3\n",
    "df.loc[pd.isnull(df['GHG_A123_m2a']) & pd.notna(df['GHG_A123']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']),'GHG_A123_m2a'] = df['GHG_A123']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#A4-A5\n",
    "df.loc[pd.isnull(df['GHG_A45_m2a']) & pd.notna(df['GHG_A45']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_A45_m2a'] = df['GHG_A45']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#A1-A5\n",
    "df.loc[pd.isnull(df['GHG_A12345_m2a']) & pd.notna(df['GHG_A12345']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_A12345_m2a'] = df['GHG_A12345']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#B1-B4\n",
    "df.loc[pd.isnull(df['GHG_B1234_m2a']) & pd.notna(df['GHG_B1234']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_B1234_m2a'] = df['GHG_B1234']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#B1-B5\n",
    "df.loc[pd.isnull(df['GHG_B12345_m2a']) & pd.notna(df['GHG_B12345']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_B12345_m2a'] = df['GHG_B12345']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#B6-B7\n",
    "df.loc[pd.isnull(df['GHG_B67_m2a']) & pd.notna(df['GHG_B67']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_B67_m2a'] = df['GHG_B67']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#B1-B7\n",
    "df.loc[pd.isnull(df['GHG_B1234567_m2a']) & pd.notna(df['GHG_B1234567']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_B1234567_m2a'] = df['GHG_B1234567']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#C1-C2\n",
    "df.loc[pd.isnull(df['GHG_C12_m2a']) & pd.notna(df['GHG_C12']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_C12_m2a'] = df['GHG_C12']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#C3-C4\n",
    "df.loc[pd.isnull(df['GHG_C34_m2a']) & pd.notna(df['GHG_C34']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_C34_m2a'] = df['GHG_C34']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#C1-C4\n",
    "df.loc[pd.isnull(df['GHG_C1234_m2a']) & pd.notna(df['GHG_C1234']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_C1234_m2a'] = df['GHG_C1234']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#C3-C4 + D\n",
    "df.loc[pd.isnull(df['GHG_C34_D_m2a']) & pd.notna(df['GHG_C34_D']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_C34_D_m2a'] = df['GHG_C34_D']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#C1-C4 + D\n",
    "df.loc[pd.isnull(df['GHG_C1234_D_m2a']) & pd.notna(df['GHG_C1234_D']) & pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_C1234_D_m2a'] = df['GHG_C1234_D']/df['bldg_area_gfa']/df['lca_RSP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3 Totals [kgCO2] => totals [kgCO2e/m2/a]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T21:33:56.997733Z",
     "start_time": "2021-06-05T21:33:56.985714Z"
    }
   },
   "outputs": [],
   "source": [
    "#Add/fill feature:\n",
    "\"\"\"\n",
    "\"Results - Totals [kgCO2e/m2/a]\"\n",
    "\"\"\"\n",
    "#based on feature(s):\n",
    "\"\"\"\n",
    "\"Results - Totals [kgCO2e]\", \"bldg_area_gfa\" and \"lca_RSP\"\n",
    "\"\"\"\n",
    "#This is done by checking that the wanted feature is NaN to avoid overwriting existing data,\n",
    "#if is NaN, it is checked whether the necessary values to fill it are not NaN,\n",
    "#if these are not NaN, they are used to calculate results in [kgCO2e/m2/a].\n",
    "#If wanted feature is already present or necessary values are NaN, the row is skipped.\n",
    "\n",
    "#sum_embodied_m2a\n",
    "df.loc[pd.isnull(df['GHG_sum_em_m2a']) & pd.notna(df['GHG_sum_em'])& pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_sum_em_m2a'] = df['GHG_sum_em']/df['bldg_area_gfa']/df['lca_RSP']\n",
    "\n",
    "#sum_operational_m2a\n",
    "df.loc[pd.isnull(df['GHG_sum_op_m2a']) & pd.notna(df['GHG_sum_op'])& pd.notna(df['bldg_area_gfa']) & pd.notna(df['lca_RSP']), 'GHG_sum_op_m2a'] = df['GHG_sum_op']/df['bldg_area_gfa']/df['lca_RSP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Add aggregated life cycle stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both in units of [kgCO2/m2/a] and [kgCO2/capita/a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T21:33:57.107439Z",
     "start_time": "2021-06-05T21:33:57.092428Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create aggregated life cycle stage features\n",
    "df['GHG_A_m2a'] = np.nan\n",
    "df['GHG_B_em_m2a'] = np.nan\n",
    "df['GHG_B_op_m2a'] = np.nan\n",
    "df['GHG_C_m2a'] = np.nan\n",
    "\n",
    "df['GHG_A_capita_a'] = np.nan\n",
    "df['GHG_B_em_capita_a'] = np.nan\n",
    "df['GHG_B_op_capita_a'] = np.nan\n",
    "df['GHG_C_capita_a'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T21:33:57.154323Z",
     "start_time": "2021-06-05T21:33:57.123345Z"
    }
   },
   "outputs": [],
   "source": [
    "#Add/fill GHG [kgCO2/m2/a]\n",
    "\n",
    "#GHG_A:\n",
    "\n",
    "\"\"\"\n",
    "#GHG_A1\n",
    "#GHG_A2\n",
    "#GHG_A3 } GHG_A123\n",
    "#GHG_A4\n",
    "#GHG_A5 } GHG_A45  } GHG_A\n",
    "\"\"\"\n",
    "\n",
    "#If GHG_A123_m2a is NaN, use GHG_A1_m2a + GHG_A2_m2a + GHG_A3_m2a\n",
    "df.loc[pd.isnull(df['GHG_A123_m2a']), 'GHG_A123_m2a'] = df['GHG_A1_m2a'].fillna(0)+df['GHG_A2_m2a'].fillna(0)+df['GHG_A3_m2a'].fillna(0)\n",
    "\n",
    "#If GHG_A45_m2a is NaN, use GHG_A4_m2a + GHG_A5_m2a\n",
    "df.loc[pd.isnull(df['GHG_A45_m2a']), 'GHG_A45_m2a'] = df['GHG_A4_m2a'].fillna(0)+df['GHG_A5_m2a'].fillna(0)\n",
    "\n",
    "#If GHG_A_m2a is NaN, use GHG_A123_m2a + GHG_A45_m2a\n",
    "df.loc[pd.isnull(df['GHG_A_m2a']), 'GHG_A_m2a'] = df['GHG_A123_m2a'].fillna(0)+df['GHG_A45_m2a'].fillna(0)\n",
    "\n",
    "##########################################\n",
    "\n",
    "#GHG_B_em:\n",
    "\n",
    "\"\"\"\n",
    "#GHG_B1\n",
    "#GHG_B2\n",
    "#GHG_B3\n",
    "#GHG_B4 } GHG_B1234  \n",
    "#GHG_B5 } GHG_B5    } GHG_B_em\n",
    "\"\"\"\n",
    "\n",
    "#If GHG_B1234_m2a is NaN, use GHG_B1_m2a + GHG_B2_m2a + GHG_B3_m2a + GHG_B4_m2a\n",
    "df.loc[pd.isnull(df['GHG_B1234_m2a']), 'GHG_B1234_m2a'] = df['GHG_B1_m2a'].fillna(0)+df['GHG_B2_m2a'].fillna(0)+df['GHG_B3_m2a'].fillna(0)+df['GHG_B4_m2a'].fillna(0)\n",
    "\n",
    "#If GHG_B_em_m2a is NaN, use GHG_B1234_m2a + GHG_B5_m2a\n",
    "df.loc[pd.isnull(df['GHG_B_em_m2a']), 'GHG_B_em_m2a'] = df['GHG_B1234_m2a'].fillna(0)+df['GHG_B5_m2a'].fillna(0)\n",
    "\n",
    "##########################################\n",
    "\n",
    "#GHG_B_op:\n",
    "\n",
    "#GHG_B6 } GHG_B_op\n",
    "\n",
    "#If GHG_B_op_m2a is NaN, use GHG_B6_m2a\n",
    "df.loc[pd.isnull(df['GHG_B_op_m2a']), 'GHG_B_op_m2a'] = df['GHG_B6_m2a'].fillna(0)+df['GHG_B7_m2a'].fillna(0)\n",
    "\n",
    "#If GHG_B67_m2a is NaN, use GHG_B6_m2a + GHG_B7_m2a\n",
    "df.loc[pd.isnull(df['GHG_B67_m2a']), 'GHG_B67_m2a'] = df['GHG_B6_m2a'].fillna(0)+df['GHG_B7_m2a'].fillna(0)\n",
    "\n",
    "#If GHG_B67_m2a is still NaN, use GHG_sum_op_m2a\n",
    "df.loc[(df['GHG_B67_m2a'] == 0), 'GHG_B67_m2a'] = df['GHG_sum_op_m2a']\n",
    "\n",
    "##########################################\n",
    "\n",
    "#GHG_C:\n",
    "\n",
    "\"\"\"\n",
    "#GHG_C1\n",
    "#GHG_C2 } GHG_C12\n",
    "#GHG_C3\n",
    "#GHG_C4 } GHG_C34 } GHG_C1234 } GHG_C\n",
    "\"\"\"\n",
    "\n",
    "#If GHG_C12_m2a is NaN, use GHG_C1_m2a + GHG_C2_m2a\n",
    "df.loc[pd.isnull(df['GHG_C12_m2a']), 'GHG_C12_m2a'] = df['GHG_C1_m2a'].fillna(0)+df['GHG_C2_m2a'].fillna(0)\n",
    "\n",
    "#If GHG_C34_m2a is NaN, use GHG_C3_m2a + GHG_C4_m2a\n",
    "df.loc[pd.isnull(df['GHG_C34_m2a']), 'GHG_C34_m2a'] = df['GHG_C3_m2a'].fillna(0)+df['GHG_C4_m2a'].fillna(0)\n",
    "\n",
    "#If GHG_1234_m2a is NaN, use GHG_C12_m2a + GHG_C34_m2a\n",
    "df.loc[pd.isnull(df['GHG_C1234_m2a']), 'GHG_C1234_m2a'] = df['GHG_C12_m2a'].fillna(0)+df['GHG_C34_m2a'].fillna(0)\n",
    "\n",
    "#If GHG_C_m2a is NaN, use GHG_C1234_m2a\n",
    "df.loc[pd.isnull(df['GHG_C_m2a']), 'GHG_C_m2a'] = df['GHG_C1234_m2a'].fillna(0)\n",
    "\n",
    "##########################################\n",
    "\n",
    "#GHG_sum_em_m2a:\n",
    "\n",
    "\"\"\"\n",
    "#GHG_A\n",
    "#GHG_B_em } GHG_sum_em\n",
    "#GHG_C\n",
    "\"\"\"\n",
    "\n",
    "#If GHG_sum_em_m2a is NaN, use GHG_A_m2a + GHG_B_em_m2a + GHG_C_m2a\n",
    "df.loc[pd.isnull(df['GHG_sum_em_m2a']), 'GHG_sum_em_m2a'] = df['GHG_A_m2a'].fillna(0)+df['GHG_B_em_m2a'].fillna(0)+df['GHG_C_m2a'].fillna(0)\n",
    "\n",
    "##########################################\n",
    "\n",
    "#Reinstate NaN instead of 0\n",
    "\n",
    "#Create list of columns to replace\n",
    "col_list = ['GHG_A1_m2a',\n",
    "            'GHG_A2_m2a',\n",
    "            'GHG_A3_m2a',\n",
    "            'GHG_A4_m2a',\n",
    "            'GHG_A5_m2a',\n",
    "            'GHG_A123_m2a',\n",
    "            'GHG_A45_m2a',\n",
    "            \n",
    "            'GHG_B1_m2a',\n",
    "            'GHG_B2_m2a',\n",
    "            'GHG_B3_m2a',\n",
    "            'GHG_B4_m2a',\n",
    "            'GHG_B5_m2a',\n",
    "            'GHG_B6_m2a',\n",
    "            'GHG_B7_m2a',\n",
    "            'GHG_B1234_m2a',\n",
    "            \n",
    "            'GHG_C1_m2a',\n",
    "            'GHG_C2_m2a',\n",
    "            'GHG_C3_m2a',\n",
    "            'GHG_C4_m2a',\n",
    "            'GHG_C12_m2a',\n",
    "            'GHG_C34_m2a'\n",
    "           ]\n",
    "\n",
    "#Loop over list of columns and replace 0 with NaN\n",
    "for col in col_list:\n",
    "    df[col].replace(to_replace=[0,\"0\"], value=np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T21:33:57.170222Z",
     "start_time": "2021-06-05T21:33:57.156259Z"
    }
   },
   "outputs": [],
   "source": [
    "#Add/fill GHG [kgCO2/capita/a]\n",
    "\n",
    "#GHG_A_capita_a:\n",
    "df['GHG_A_capita_a'] = df['GHG_A_m2a']*df['bldg_area_gfa']/df['bldg_users_total']\n",
    "\n",
    "#GHG_B_em_capita_a:\n",
    "df['GHG_B_em_capita_a'] = df['GHG_B_em_m2a']*df['bldg_area_gfa']/df['bldg_users_total']\n",
    "\n",
    "#GHG_B_op_capita_a:\n",
    "df['GHG_B_op_capita_a'] = df['GHG_B_op_m2a']*df['bldg_area_gfa']/df['bldg_users_total']\n",
    "\n",
    "#GHG_C_capita_a:\n",
    "df['GHG_C_capita_a'] = df['GHG_C_m2a']*df['bldg_area_gfa']/df['bldg_users_total']\n",
    "\n",
    "#GHG_sum_em_capita_a:\n",
    "df['GHG_sum_em_capita_a'] = df['GHG_sum_em_m2a']*df['bldg_area_gfa']/df['bldg_users_total']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Add new aggregated scope features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1 Life cycle stage (LCS) scope feature**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1.1 Life cycle stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to build a string based on:\n",
    "<br>- **A**\n",
    "<br>- **B**\n",
    "<br>- **C**\n",
    "<br>- **D**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T21:33:57.201195Z",
     "start_time": "2021-06-05T21:33:57.172235Z"
    }
   },
   "outputs": [],
   "source": [
    "#Initiate new feature\n",
    "df['scope_LCS'] = \"\"\n",
    "\n",
    "#Add 'A' to string if one of the conditions are true\n",
    "df.loc[(df['scope_LCS_A123'] == 'Yes')|\n",
    "       (df['scope_LCS_A4'] == 'Yes')|\n",
    "       (df['scope_LCS_A5'] == 'Yes'), 'scope_LCS'] = 'A'\n",
    "\n",
    "#Add 'B' to string if one of the conditions are true\n",
    "df.loc[(df['scope_LCS_B1'] == 'Yes')|\n",
    "       (df['scope_LCS_B2'] == 'Yes')|\n",
    "       (df['scope_LCS_B3'] == 'Yes')|\n",
    "       (df['scope_LCS_B4'] == 'Yes')|\n",
    "       (df['scope_LCS_B5'] == 'Yes')|\n",
    "       (df['scope_LCS_B6'] == 'Yes')|\n",
    "       (df['scope_LCS_B7'] == 'Yes'), 'scope_LCS'] = df['scope_LCS']+'B'\n",
    "\n",
    "#Add 'C' to string if one of the conditions are true\n",
    "df.loc[(df['scope_LCS_C1'] == 'Yes')|\n",
    "       (df['scope_LCS_C2'] == 'Yes')|\n",
    "       (df['scope_LCS_C3'] == 'Yes')|\n",
    "       (df['scope_LCS_C4'] == 'Yes'), 'scope_LCS'] = df['scope_LCS']+'C'\n",
    "\n",
    "#Add 'D' to string if one of the conditions are true\n",
    "df.loc[(df['scope_LCS_D'] == 'Yes'), 'scope_LCS'] = df['scope_LCS']+'D'\n",
    "\n",
    "#If none of the conditions are true, data will be empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1.2 Life cycle modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to build a string based on:\n",
    "<br>- A1-3: **P**roduction\n",
    "<br>- A4-5: **C**onstruction process\n",
    "<br>- B1-4: **M**aintenance, repair, replacement\n",
    "<br>- B5: **R**efurbishment\n",
    "<br>- B6-7: **O**perational energy & water use\n",
    "<br>- C1-2: **D**econstruction, transport\n",
    "<br>- C3-4: **W**aste processing and disposal\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T21:33:57.233051Z",
     "start_time": "2021-06-05T21:33:57.202135Z"
    }
   },
   "outputs": [],
   "source": [
    "#Initiate new feature\n",
    "df['scope_LCM'] = \"\"\n",
    "\n",
    "#Add 'P' to string if the condition is true\n",
    "df.loc[(df['scope_LCS_A123'] == 'Yes'), 'scope_LCM'] = 'P'\n",
    "\n",
    "#Add 'C' to string if one of the conditions are true\n",
    "df.loc[(df['scope_LCS_A4'] == 'Yes')|\n",
    "       (df['scope_LCS_A5'] == 'Yes'), 'scope_LCM'] = df['scope_LCM']+'C'\n",
    "\n",
    "#Add 'M' to string if one of the conditions are true\n",
    "df.loc[(df['scope_LCS_B1'] == 'Yes')|\n",
    "       (df['scope_LCS_B2'] == 'Yes')|\n",
    "       (df['scope_LCS_B3'] == 'Yes')|\n",
    "       (df['scope_LCS_B4'] == 'Yes'), 'scope_LCM'] = df['scope_LCM']+'M'\n",
    "\n",
    "#Add 'R' to string if one of the conditions are true\n",
    "df.loc[(df['scope_LCS_B5'] == 'Yes'), 'scope_LCM'] = df['scope_LCM']+'R'\n",
    "\n",
    "#Add 'O' to string if one of the conditions are true\n",
    "df.loc[(df['scope_LCS_B6'] == 'Yes')|\n",
    "       (df['scope_LCS_B7'] == 'Yes'), 'scope_LCM'] = df['scope_LCM']+'O'\n",
    "\n",
    "#Add 'D' to string if one of the conditions are true\n",
    "df.loc[(df['scope_LCS_C1'] == 'Yes')|\n",
    "       (df['scope_LCS_C2'] == 'Yes'), 'scope_LCM'] = df['scope_LCM']+'D'\n",
    "\n",
    "#Add 'W' to string if one of the conditions are true\n",
    "df.loc[(df['scope_LCS_C3'] == 'Yes')|\n",
    "       (df['scope_LCS_C4'] == 'Yes'), 'scope_LCM'] = df['scope_LCM']+'W'\n",
    "\n",
    "#If none of the conditions are true, data will be empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2 Building parts scope feature**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to build a string based on:\n",
    "<br>- **G**round (1) (i.e. substructure, foundation, basement walls, etc.)\n",
    "<br>- **L**oad-bearing structure (2) (i.e. structural frame, walls, floors, roofs, etc.)\n",
    "<br>- **E**nvelope (3, 4) (i.e. openings, ext. finishes, etc.)\n",
    "<br>- **I**nternal (4) (i.e. partitions, int. finishes, etc.)\n",
    "<br>- **S**ervices (5,6) (i.e. mechanical, electrical, renew. energy, etc.)\n",
    "<br>- **A**ppliances (7,8) (i.e. fixed facilities, mobile fittings, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T21:33:57.264005Z",
     "start_time": "2021-06-05T21:33:57.235046Z"
    }
   },
   "outputs": [],
   "source": [
    "#Initiate new feature\n",
    "df['scope_parts'] = \"\"\n",
    "\n",
    "#Add 'G' to string if the condition is true\n",
    "df.loc[(df['scope_parts_1_ground'] == 'Yes'), 'scope_parts'] = 'G'\n",
    "\n",
    "#Add 'L' to string if the condition is true\n",
    "df.loc[(df['scope_parts_2_structure'] == 'Yes'), 'scope_parts'] = df['scope_parts']+'L'\n",
    "\n",
    "#Add 'E' to string if one of the conditions are true\n",
    "df.loc[(df['scope_parts_3_secondary'] == 'Yes'), 'scope_parts'] = df['scope_parts']+'E'\n",
    "\n",
    "#Add 'I' to string if the condition is true\n",
    "df.loc[(df['scope_parts_4_finishes'] == 'Yes'), 'scope_parts'] = df['scope_parts']+'I'\n",
    "\n",
    "#Add 'S' to string if one of the conditions are true\n",
    "df.loc[(df['scope_parts_5_mechanical'] == 'Yes')|\n",
    "       (df['scope_parts_6_electrical'] == 'Yes')|\n",
    "       (df['scope_parts_6+_renewables'] == 'Yes'), 'scope_parts'] = df['scope_parts']+'S'\n",
    "\n",
    "#Add 'A' to string if one of the conditions are true\n",
    "df.loc[(df['scope_parts_7_facilities'] == 'Yes')|\n",
    "       (df['scope_parts_8_fittings'] == 'Yes'), 'scope_parts'] = df['scope_parts']+'A'\n",
    "\n",
    "#If none of the conditions are true, data will be empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Add material/mass features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add/fill feature: \"inv_mat_mass_total_m2\"\n",
    "<br>based on feature(s): \"inv_mat_mass_total\" & \"bldg_area_gfa\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total mass per m2\n",
    "df.loc[pd.notna(df['inv_mat_mass_total']) & pd.notna(df['bldg_area_gfa']), 'inv_mat_mass_total_m2'] = df['inv_mat_mass_total']/df['bldg_area_gfa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add/fill feature: \"inv_mat_mass_total_capita\"\n",
    "<br>based on feature(s): \"inv_mat_mass_total\" & \"bldg_users_total\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total mass per capita\n",
    "df.loc[pd.notna(df['inv_mat_mass_total']) & pd.notna(df['bldg_users_total']), 'inv_mat_mass_total_capita'] = df['inv_mat_mass_total']/df['bldg_users_total']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create new material quantity and intensity features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create features based on the following categories\n",
    "<br>\n",
    "<br>**Custom mass categories:**\n",
    "<br>Aluminium (e.g., alum alloy)\n",
    "<br>Bamboo\n",
    "<br>Brass, copper\n",
    "<br>Cement mortar, plaster\n",
    "<br>Ceramics (e.g., fired clay bricks)\n",
    "<br>Concrete reinforced\n",
    "<br>Concrete w/o reinforcement\n",
    "<br>Earth (e.g., unfired clay, adobe, rammed earth, etc.)\n",
    "<br>EPS or XPS (insulation)\n",
    "<br>Fungi (e.g. Mycelium)\n",
    "<br>Glass (single, double, triple)\n",
    "<br>Metals (iron, steel)\n",
    "<br>Plastics (various: PC, PE, PP, PU, PVC)\n",
    "<br>Steel (reinforcement)\n",
    "<br>Stone (granite, limestone, etc)\n",
    "<br>Stone wool (e.g. insulation)\n",
    "<br>Straw or hemp (e.g., strawbale)\n",
    "<br>Timber, wood\n",
    "<br>Other\n",
    "<br>No data\n",
    "<br>\n",
    "<br>**EUROSTAT mass categories:**\n",
    "<br>1. Metal materials\n",
    "<br>2. Non-metallic minerals\n",
    "<br>3. Fossil energy materials\n",
    "<br>4. Biomass based materials\n",
    "<br>No data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom categories are filled in using the data in the dataset.\n",
    "<br>The EUROSTAT categories are infered by looking at the custom categories and using the associations from the DataCollection 'meta' sheet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom mass categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list with existing material category labels\n",
    "mat_category_list = ['Aluminium (e.g., alum alloy)',\n",
    "                    'Bamboo',\n",
    "                    'Brass, copper',\n",
    "                    'Cement mortar, plaster',\n",
    "                    'Ceramics (e.g., fired clay bricks)',\n",
    "                    'Concrete reinforced',\n",
    "                    'Concrete w/o reinforcement',\n",
    "                    'Earth (e.g., unfired clay, adobe, rammed earth, etc.)',\n",
    "                    'EPS or XPS (insulation)',\n",
    "                    'Fungi (e.g. Mycelium)',\n",
    "                    'Glass (single, double, triple)',\n",
    "                    'Metals (iron, steel)',\n",
    "                    'Plastics (various: PC, PE, PP, PU, PVC)',\n",
    "                    'Steel (reinforcement)',\n",
    "                    'Stone (granite, limestone, etc)',\n",
    "                    'Stone wool (e.g. insulation)',\n",
    "                    'Straw or hemp (e.g., strawbale)',\n",
    "                    'Timber, wood',\n",
    "                    'Other']\n",
    "\n",
    "#Iterate through each columns label and create a new column with the sum of the mass of the specified material category\n",
    "for mat_category in mat_category_list:\n",
    "\n",
    "    #Initiate new column\n",
    "    df[mat_category] = 0\n",
    "\n",
    "    #Check 1st material and add if conditions are met\n",
    "    df.loc[(df['inv_mat_1_type'] == mat_category) & pd.notna(df['inv_mat_1_mass']), mat_category] = df[mat_category] + df['inv_mat_1_mass']\n",
    "\n",
    "    #Check 2nd material and add if conditions are met\n",
    "    df.loc[(df['inv_mat_2_type'] == mat_category) & pd.notna(df['inv_mat_2_mass']), mat_category] = df[mat_category] + df['inv_mat_2_mass']\n",
    "\n",
    "    #Check 3rd material and add if conditions are met\n",
    "    df.loc[(df['inv_mat_3_type'] == mat_category) & pd.notna(df['inv_mat_3_mass']), mat_category] = df[mat_category] + df['inv_mat_3_mass']\n",
    "\n",
    "    #Check 4th material and add if conditions are met\n",
    "    df.loc[(df['inv_mat_4_type'] == mat_category) & pd.notna(df['inv_mat_4_mass']), mat_category] = df[mat_category] + df['inv_mat_4_mass']\n",
    "\n",
    "    #Check 5th material and add if conditions are met\n",
    "    df.loc[(df['inv_mat_5_type'] == mat_category) & pd.notna(df['inv_mat_5_mass']), mat_category] = df[mat_category] + df['inv_mat_5_mass']\n",
    "\n",
    "#Rename the category labels into simplified versions\n",
    "dict_1 = {\n",
    "'Aluminium (e.g., alum alloy)':'mass_aluminium',\n",
    "'Bamboo':'mass_bamboo',\n",
    "'Brass, copper':'mass_brass_copper',\n",
    "'Cement mortar, plaster':'mass_cement_mortar',\n",
    "'Ceramics (e.g., fired clay bricks)':'mass_ceramics',\n",
    "'Concrete reinforced':'mass_concrete_reinforced',\n",
    "'Concrete w/o reinforcement':'mass_concrete_wo_reinforcement',\n",
    "'Earth (e.g., unfired clay, adobe, rammed earth, etc.)':'mass_earth',\n",
    "'EPS or XPS (insulation)':'mass_EPS_XPS',\n",
    "'Fungi (e.g. Mycelium)':'mass_fungi',\n",
    "'Glass (single, double, triple)':'mass_glass',\n",
    "'Metals (iron, steel)':'mass_metals',\n",
    "'Plastics (various: PC, PE, PP, PU, PVC)':'mass_plastics',\n",
    "'Steel (reinforcement)':'mass_steel_reinforcement',\n",
    "'Stone (granite, limestone, etc)':'mass_stone',\n",
    "'Stone wool (e.g. insulation)':'mass_stone_wool',\n",
    "'Straw or hemp (e.g., strawbale)':'mass_straw_hemp',\n",
    "'Timber, wood':'mass_wood',\n",
    "'Other':'mass_other'\n",
    "}    \n",
    "\n",
    "df.rename(columns = dict_1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EUROSTAT mass categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['eurostat_metal_materials'] = (df['mass_aluminium'] + df['mass_brass_copper'] + df['mass_metals'] + df['mass_steel_reinforcement'])\n",
    "df['eurostat_non-metallic_minerals'] = (df['mass_cement_mortar'] + df['mass_ceramics'] + df['mass_concrete_reinforced'] + df['mass_concrete_wo_reinforcement'] + df['mass_earth'] + df['mass_glass'] + df['mass_stone'] + df['mass_stone_wool'])\n",
    "df['eurostat_fossil_energy_materials'] = (df['mass_EPS_XPS'] + df['mass_plastics'])\n",
    "df['eurostat_biomass_based_materials'] = (df['mass_bamboo'] + df['mass_fungi'] + df['mass_straw_hemp'] + df['mass_wood'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create sum of mass of top 5 materials**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['inv_mat_mass_sum_top_5'] = 0\n",
    "\n",
    "#Check 1st material and add if conditions are met\n",
    "df.loc[pd.notna(df['inv_mat_1_mass']), 'inv_mat_mass_sum_top_5'] = df['inv_mat_mass_sum_top_5'] + df['inv_mat_1_mass']\n",
    "\n",
    "#Check 2nd material and add if conditions are met\n",
    "df.loc[pd.notna(df['inv_mat_2_mass']), 'inv_mat_mass_sum_top_5'] = df['inv_mat_mass_sum_top_5'] + df['inv_mat_2_mass']\n",
    "\n",
    "#Check 3rd material and add if conditions are met\n",
    "df.loc[pd.notna(df['inv_mat_3_mass']), 'inv_mat_mass_sum_top_5'] = df['inv_mat_mass_sum_top_5'] + df['inv_mat_3_mass']\n",
    "\n",
    "#Check 4th material and add if conditions are met\n",
    "df.loc[pd.notna(df['inv_mat_4_mass']), 'inv_mat_mass_sum_top_5'] = df['inv_mat_mass_sum_top_5'] + df['inv_mat_4_mass']\n",
    "\n",
    "#Check 5th material and add if conditions are met\n",
    "df.loc[pd.notna(df['inv_mat_5_mass']), 'inv_mat_mass_sum_top_5'] = df['inv_mat_mass_sum_top_5'] + df['inv_mat_5_mass']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create ratio between 'sum of mass of top 5 materials' and total mass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['inv_mat_mass_ratio'] = 100*df['inv_mat_mass_sum_top_5']/df['inv_mat_mass_total']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Add other features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add/fill \"gfa m2 per capita\" feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T21:33:57.279927Z",
     "start_time": "2021-06-05T21:33:57.265964Z"
    }
   },
   "outputs": [],
   "source": [
    "#gfa m2 per capita  \n",
    "df.loc[pd.notna(df['bldg_area_gfa']) & pd.notna(df['bldg_users_total']), 'gfa_m2_capita'] = df['bldg_area_gfa']/df['bldg_users_total']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add/infer \"bldg_energy_class_general\" based on \"inv_energy_consumption\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Existing standard\n",
    "df.loc[(pd.isnull(df['bldg_energy_class_general']) | (df['bldg_energy_class_general'] == 'No data')) & pd.notna(df['inv_energy_consumption']) & (df['inv_energy_consumption'] >= 100.0), 'bldg_energy_class_general'] = 'Existing Standard'\n",
    "\n",
    "#New standard\n",
    "df.loc[(pd.isnull(df['bldg_energy_class_general']) | (df['bldg_energy_class_general'] == 'No data')) & pd.notna(df['inv_energy_consumption']) & (df['inv_energy_consumption'] > 20.0) & (df['inv_energy_consumption'] < 100.0), 'bldg_energy_class_general'] = 'New Standard'\n",
    "\n",
    "#Advanced new standard\n",
    "df.loc[(pd.isnull(df['bldg_energy_class_general']) | (df['bldg_energy_class_general'] == 'No data')) & pd.notna(df['inv_energy_consumption']) & (df['inv_energy_consumption'] <= 20.0), 'bldg_energy_class_general'] = 'New Advanced'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add/infer \"bldg_year_complete_interval\" based on \"bldg_year_complete\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2020-Today\n",
    "df.loc[(pd.isnull(df['bldg_year_complete_interval']) | (df['bldg_year_complete_interval'] == 'No data')) & pd.notna(df['bldg_year_complete']) & (df['bldg_year_complete'] >= 2020), 'bldg_year_complete_interval'] = '2020-Today'\n",
    "\n",
    "#2015-2019\n",
    "df.loc[(pd.isnull(df['bldg_year_complete_interval']) | (df['bldg_year_complete_interval'] == 'No data')) & pd.notna(df['bldg_year_complete']) & (df['bldg_year_complete'] >= 2015) & (df['bldg_year_complete'] <= 2019), 'bldg_year_complete_interval'] = '2015-2019'\n",
    "\n",
    "#2010-2014\n",
    "df.loc[(pd.isnull(df['bldg_year_complete_interval']) | (df['bldg_year_complete_interval'] == 'No data')) & pd.notna(df['bldg_year_complete']) & (df['bldg_year_complete'] >= 2010) & (df['bldg_year_complete'] <= 2014), 'bldg_year_complete_interval'] = '2010-2014'\n",
    "\n",
    "#2005-2009\n",
    "df.loc[(pd.isnull(df['bldg_year_complete_interval']) | (df['bldg_year_complete_interval'] == 'No data')) & pd.notna(df['bldg_year_complete']) & (df['bldg_year_complete'] >= 2005) & (df['bldg_year_complete'] <= 2009), 'bldg_year_complete_interval'] = '2005-2009'\n",
    "\n",
    "#2000-2004\n",
    "df.loc[(pd.isnull(df['bldg_year_complete_interval']) | (df['bldg_year_complete_interval'] == 'No data')) & pd.notna(df['bldg_year_complete']) & (df['bldg_year_complete'] >= 2000) & (df['bldg_year_complete'] <= 2004), 'bldg_year_complete_interval'] = '2000-2004'\n",
    "\n",
    "#1995-1999\n",
    "df.loc[(pd.isnull(df['bldg_year_complete_interval']) | (df['bldg_year_complete_interval'] == 'No data')) & pd.notna(df['bldg_year_complete']) & (df['bldg_year_complete'] >= 1995) & (df['bldg_year_complete'] <= 1999), 'bldg_year_complete_interval'] = '1995-1999'\n",
    "\n",
    "#1990-1994\n",
    "df.loc[(pd.isnull(df['bldg_year_complete_interval']) | (df['bldg_year_complete_interval'] == 'No data')) & pd.notna(df['bldg_year_complete']) & (df['bldg_year_complete'] >= 1990) & (df['bldg_year_complete'] <= 1994), 'bldg_year_complete_interval'] = '1990-1994'\n",
    "\n",
    "#1985-1989\n",
    "df.loc[(pd.isnull(df['bldg_year_complete_interval']) | (df['bldg_year_complete_interval'] == 'No data')) & pd.notna(df['bldg_year_complete']) & (df['bldg_year_complete'] >= 1985) & (df['bldg_year_complete'] <= 1989), 'bldg_year_complete_interval'] = '1985-1989'\n",
    "\n",
    "#1980-1984\n",
    "df.loc[(pd.isnull(df['bldg_year_complete_interval']) | (df['bldg_year_complete_interval'] == 'No data')) & pd.notna(df['bldg_year_complete']) & (df['bldg_year_complete'] >= 1980) & (df['bldg_year_complete'] <= 1984), 'bldg_year_complete_interval'] = '1980-1984'\n",
    "\n",
    "#1975-1979\n",
    "df.loc[(pd.isnull(df['bldg_year_complete_interval']) | (df['bldg_year_complete_interval'] == 'No data')) & pd.notna(df['bldg_year_complete']) & (df['bldg_year_complete'] >= 1975) & (df['bldg_year_complete'] <= 1979), 'bldg_year_complete_interval'] = '1975-1979'\n",
    "\n",
    "#1970-1974\n",
    "df.loc[(pd.isnull(df['bldg_year_complete_interval']) | (df['bldg_year_complete_interval'] == 'No data')) & pd.notna(df['bldg_year_complete']) & (df['bldg_year_complete'] >= 1970) & (df['bldg_year_complete'] <= 1974), 'bldg_year_complete_interval'] = '1970-1974'\n",
    "\n",
    "#1965-1969\n",
    "df.loc[(pd.isnull(df['bldg_year_complete_interval']) | (df['bldg_year_complete_interval'] == 'No data')) & pd.notna(df['bldg_year_complete']) & (df['bldg_year_complete'] >= 1965) & (df['bldg_year_complete'] <= 1969), 'bldg_year_complete_interval'] = '1965-1969'\n",
    "\n",
    "#1960-1964\n",
    "df.loc[(pd.isnull(df['bldg_year_complete_interval']) | (df['bldg_year_complete_interval'] == 'No data')) & pd.notna(df['bldg_year_complete']) & (df['bldg_year_complete'] >= 1960) & (df['bldg_year_complete'] <= 1964), 'bldg_year_complete_interval'] = '1960-1964'\n",
    "\n",
    "#1955-1959\n",
    "df.loc[(pd.isnull(df['bldg_year_complete_interval']) | (df['bldg_year_complete_interval'] == 'No data')) & pd.notna(df['bldg_year_complete']) & (df['bldg_year_complete'] >= 1955) & (df['bldg_year_complete'] <= 1959), 'bldg_year_complete_interval'] = '1955-1959'\n",
    "\n",
    "#1950-1954\n",
    "df.loc[(pd.isnull(df['bldg_year_complete_interval']) | (df['bldg_year_complete_interval'] == 'No data')) & pd.notna(df['bldg_year_complete']) & (df['bldg_year_complete'] >= 1950) & (df['bldg_year_complete'] <= 1954), 'bldg_year_complete_interval'] = '1950-1954'\n",
    "\n",
    "#1945-1949\n",
    "df.loc[(pd.isnull(df['bldg_year_complete_interval']) | (df['bldg_year_complete_interval'] == 'No data')) & pd.notna(df['bldg_year_complete']) & (df['bldg_year_complete'] >= 1945) & (df['bldg_year_complete'] <= 1949), 'bldg_year_complete_interval'] = '1945-1949'\n",
    "\n",
    "#1940-1944\n",
    "df.loc[(pd.isnull(df['bldg_year_complete_interval']) | (df['bldg_year_complete_interval'] == 'No data')) & pd.notna(df['bldg_year_complete']) & (df['bldg_year_complete'] >= 1940) & (df['bldg_year_complete'] <= 1944), 'bldg_year_complete_interval'] = '1940-1944'\n",
    "\n",
    "#1935-1939\n",
    "df.loc[(pd.isnull(df['bldg_year_complete_interval']) | (df['bldg_year_complete_interval'] == 'No data')) & pd.notna(df['bldg_year_complete']) & (df['bldg_year_complete'] >= 1935) & (df['bldg_year_complete'] <= 1939), 'bldg_year_complete_interval'] = '1935-1939'\n",
    "\n",
    "#1930-1934\n",
    "df.loc[(pd.isnull(df['bldg_year_complete_interval']) | (df['bldg_year_complete_interval'] == 'No data')) & pd.notna(df['bldg_year_complete']) & (df['bldg_year_complete'] >= 1930) & (df['bldg_year_complete'] <= 1934), 'bldg_year_complete_interval'] = '1930-1934'\n",
    "\n",
    "#<1930\n",
    "df.loc[(pd.isnull(df['bldg_year_complete_interval']) | (df['bldg_year_complete_interval'] == 'No data')) & pd.notna(df['bldg_year_complete']) & (df['bldg_year_complete'] < 1930), 'bldg_year_complete_interval'] = '<1930'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add aggregation of GHG results on building parts from being divided into LCS to sum of entire life cycle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P1\n",
    "df.loc[pd.isnull(df['GHG_P1_sum_m2a']), 'GHG_P1_sum_m2a'] = df['GHG_P1_A123_m2a'].fillna(0) + df['GHG_P1_A45_m2a'].fillna(0) + df['GHG_P1_B1234_m2a'].fillna(0) + df['GHG_P1_B5_m2a'].fillna(0) + df['GHG_P1_C12_m2a'].fillna(0) + df['GHG_P1_C34_m2a'].fillna(0)\n",
    "\n",
    "#P2\n",
    "df.loc[pd.isnull(df['GHG_P2_sum_m2a']), 'GHG_P2_sum_m2a'] = df['GHG_P2_A123_m2a'].fillna(0) + df['GHG_P2_A45_m2a'].fillna(0) + df['GHG_P2_B1234_m2a'].fillna(0) + df['GHG_P2_B5_m2a'].fillna(0) + df['GHG_P2_C12_m2a'].fillna(0) + df['GHG_P2_C34_m2a'].fillna(0)\n",
    "\n",
    "#P34\n",
    "df.loc[pd.isnull(df['GHG_P34_sum_m2a']), 'GHG_P34_sum_m2a'] = df['GHG_P34_A123_m2a'].fillna(0) + df['GHG_P34_A45_m2a'].fillna(0) + df['GHG_P34_B1234_m2a'].fillna(0) + df['GHG_P34_B5_m2a'].fillna(0) + df['GHG_P34_C12_m2a'].fillna(0) + df['GHG_P34_C34_m2a'].fillna(0)\n",
    "\n",
    "#P4\n",
    "df.loc[pd.isnull(df['GHG_P4_sum_m2a']), 'GHG_P4_sum_m2a'] = df['GHG_P4_A123_m2a'].fillna(0) + df['GHG_P4_A45_m2a'].fillna(0) + df['GHG_P4_B1234_m2a'].fillna(0) + df['GHG_P4_B5_m2a'].fillna(0) + df['GHG_P4_C12_m2a'].fillna(0) + df['GHG_P4_C34_m2a'].fillna(0)\n",
    "\n",
    "#P56\n",
    "df.loc[pd.isnull(df['GHG_P56_sum_m2a']), 'GHG_P56_sum_m2a'] = df['GHG_P56_A123_m2a'].fillna(0) + df['GHG_P56_A45_m2a'].fillna(0) + df['GHG_P56_B1234_m2a'].fillna(0) + df['GHG_P56_B5_m2a'].fillna(0) + df['GHG_P56_C12_m2a'].fillna(0) + df['GHG_P56_C34_m2a'].fillna(0)\n",
    "        \n",
    "#P78\n",
    "df.loc[pd.isnull(df['GHG_P78_sum_m2a']), 'GHG_P78_sum_m2a'] = df['GHG_P78_A123_m2a'].fillna(0) + df['GHG_P78_A45_m2a'].fillna(0) + df['GHG_P78_B1234_m2a'].fillna(0) + df['GHG_P78_B5_m2a'].fillna(0) + df['GHG_P78_C12_m2a'].fillna(0) + df['GHG_P78_C34_m2a'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create variants on GHG reference units**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T21:33:57.310843Z",
     "start_time": "2021-06-05T21:33:57.280925Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create variants on GHG reference units\n",
    "'''\n",
    "Relevant parameters to process\n",
    "'GHG_sum_em',\n",
    "'GHG_sum_em_m2a',\n",
    "'GHG_sum_em_capita_a',\n",
    "\n",
    "'GHG_B67_m2a' #defacto sum_op_m2a\n",
    "'GHG_B_op_capita_a'\n",
    "'''\n",
    "#Change values from 0 to NaN\n",
    "\n",
    "#Create list of columns without 'bldg_floors_bg'\n",
    "col_list = list(df.drop('bldg_floors_bg',axis=1).columns)\n",
    "\n",
    "#Loop over list of columns and replace 0 with NaN\n",
    "for col in col_list:\n",
    "    df[col].replace(to_replace=[0,\"0\"], value=np.nan, inplace=True)\n",
    "\n",
    "\n",
    "# m2 per t CO2 (per year / full LCS)\n",
    "df['GHG_sum_em_m2pertonGHG_a'] = 1 / df['GHG_sum_em_m2a'] * 1000\n",
    "df['GHG_sum_em_m2pertonGHG'] = 1 / (df['GHG_sum_em_m2a'] * df['lca_RSP']) * 1000\n",
    "df['GHG_sum_op_m2pertonGHG_a'] = 1 / df['GHG_B67_m2a'] * 1000\n",
    "df['GHG_sum_op_m2pertonGHG'] = 1 / (df['GHG_B67_m2a'] * df['lca_RSP']) * 1000\n",
    "\n",
    "# users per t CO2 (per year / full LCS)\n",
    "df['GHG_sum_em_cappertonGHG_a'] = 1 / df['GHG_sum_em_capita_a'] * 1000\n",
    "df['GHG_sum_em_cappertonGHG'] = 1 / (df['GHG_sum_em_capita_a'] * df['lca_RSP']) * 1000\n",
    "df['GHG_sum_op_cappertonGHG_a'] = 1 / df['GHG_B_op_capita_a'] * 1000\n",
    "df['GHG_sum_op_cappertonGHG'] = 1 / (df['GHG_B_op_capita_a'] * df['lca_RSP']) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T21:33:57.341761Z",
     "start_time": "2021-06-05T21:33:57.311842Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(df['GHG_sum_em_m2pertonGHG_a'].describe().count)\n",
    "#print(df['GHG_sum_em_m2pertonGHG'].describe().count)\n",
    "#print(df['GHG_sum_em_cappertonGHG_a'].describe().count)\n",
    "#print(df['GHG_sum_em_cappertonGHG'].describe().count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Harmonize GHG results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Undo original APEN data harmonization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ghg_EUECB  = ghg_APEN * 50 / RSP_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#METHOD 1 (DISABLED)\n",
    "#Create new column for undoing of APEN data harmonization\n",
    "#df['GHG_A123_m2a_APEN_undo'] = (df['GHG_A123_m2a_APEN']*50)/df['lca_RSP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#METHOD2\n",
    "#Or, add undoing of APEN data harmonization to existing column\n",
    "#A123\n",
    "df.loc[pd.notna(df['GHG_A123_m2a_APEN']) & pd.isnull(df['GHG_A123_m2a']),'GHG_A123_m2a'] = (df['GHG_A123_m2a_APEN']*50)/df['lca_RSP']\n",
    "#A45\n",
    "df.loc[pd.notna(df['GHG_A45_m2a_APEN']) & pd.isnull(df['GHG_A45_m2a']),'GHG_A45_m2a'] = (df['GHG_A45_m2a_APEN']*50)/df['lca_RSP']\n",
    "#B1234\n",
    "df.loc[pd.notna(df['GHG_B1234_m2a_APEN']) & pd.isnull(df['GHG_B1234_m2a']),'GHG_B1234_m2a'] = (df['GHG_B1234_m2a_APEN']*50)/df['lca_RSP']\n",
    "#B67\n",
    "df.loc[pd.notna(df['GHG_B67_m2a_APEN']) & pd.isnull(df['GHG_B67_m2a']),'GHG_B67_m2a'] = (df['GHG_B67_m2a_APEN']*50)/df['lca_RSP']\n",
    "#C12\n",
    "df.loc[pd.notna(df['GHG_C12_m2a_APEN']) & pd.isnull(df['GHG_C12_m2a']),'GHG_C12_m2a'] = (df['GHG_C12_m2a_APEN']*50)/df['lca_RSP']\n",
    "#C34\n",
    "df.loc[pd.notna(df['GHG_C34_m2a_APEN']) & pd.isnull(df['GHG_C34_m2a']),'GHG_C34_m2a'] = (df['GHG_C34_m2a_APEN']*50)/df['lca_RSP']\n",
    "#D\n",
    "df.loc[pd.notna(df['GHG_D_m2a_APEN']) & pd.isnull(df['GHG_D_m2a']),'GHG_D_m2a'] = (df['GHG_D_m2a_APEN']*50)/df['lca_RSP']\n",
    "#sum_em\n",
    "df.loc[pd.notna(df['GHG_sum_em_m2a_APEN']) & pd.isnull(df['GHG_sum_em_m2a']),'GHG_sum_em_m2a'] = (df['GHG_sum_em_m2a_APEN']*50)/df['lca_RSP']\n",
    "#sum_op\n",
    "df.loc[pd.notna(df['GHG_sum_op_m2a_APEN']) & pd.isnull(df['GHG_sum_op_m2a']),'GHG_sum_op_m2a'] = (df['GHG_sum_op_m2a_APEN']*50)/df['lca_RSP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Apply harmonization procedure to all data that is already disaggregated, and compute the harmonized sum of EC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Harmonize GHG results per LCS**\n",
    "<br><br>\n",
    "**EC original RSP**\n",
    "<br>GHG_A_m2 = GHG_A_m2a x case_RSP\n",
    "<br>GHG_B_em_m2 = GHG_B_em_m2a x case_RSP\n",
    "<br>GHG_C_m2 = GHG_C_m2a x case_RSP\n",
    "<br>\n",
    "\n",
    "**EC harmonized RSP**\n",
    "<br>GHG_A_m2_harm =  GHG_A_m2\n",
    "<br>GHG_B_em_m2_harm = GHG_B_em_m2 x (harm_RSP/case_RSP)\n",
    "<br>GHG_C_m2_harm = GHG_C_m2\n",
    "<br>\n",
    "<br>**EC harmonized annualized**\n",
    "<br>GHG_A_m2a_harm = GHG_A_m2_harm / RSP_harm \n",
    "<br>GHG_B_em_m2a_harm = GHG_B_em_m2_harm / RSP_harm \n",
    "<br>GHG_C_m2a_harm = GHG_C_m2_harm / RSP_harm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define harmonized life cycle study period\n",
    "lca_RSP_harm = 50\n",
    "\n",
    "### Scale up by reference study period ###\n",
    "\n",
    "#GHG_A123_m2\n",
    "df.loc[pd.notna(df['GHG_A123_m2a']) & pd.notna(df['lca_RSP']), 'GHG_A123_m2'] = df['GHG_A123_m2a'] * df['lca_RSP']\n",
    "\n",
    "#GHG_A45_m2\n",
    "df.loc[pd.notna(df['GHG_A45_m2a']) & pd.notna(df['lca_RSP']), 'GHG_A45_m2'] = df['GHG_A45_m2a'] * df['lca_RSP']\n",
    "\n",
    "#GHG_B1234_m2\n",
    "df.loc[pd.notna(df['GHG_B1234_m2a']) & pd.notna(df['lca_RSP']), 'GHG_B1234_m2'] = (df['GHG_B1234_m2a'] * df['lca_RSP'])\n",
    "\n",
    "#GHG_B5_m2\n",
    "df.loc[pd.notna(df['GHG_B5_m2a']) & pd.notna(df['lca_RSP']), 'GHG_B5_m2'] = (df['GHG_B5_m2a'] * df['lca_RSP'])\n",
    "\n",
    "#GHG_B67_m2\n",
    "df.loc[pd.notna(df['GHG_B67_m2a']) & pd.notna(df['lca_RSP']), 'GHG_B67_m2'] = (df['GHG_B67_m2a'] * df['lca_RSP'])\n",
    "\n",
    "#GHG_C12_m2\n",
    "df.loc[pd.notna(df['GHG_C12_m2a']) & pd.notna(df['lca_RSP']), 'GHG_C12_m2'] = df['GHG_C12_m2a'] * df['lca_RSP']\n",
    "\n",
    "#GHG_C34_m2\n",
    "df.loc[pd.notna(df['GHG_C34_m2a']) & pd.notna(df['lca_RSP']), 'GHG_C34_m2'] = df['GHG_C34_m2a'] * df['lca_RSP']\n",
    "\n",
    "\n",
    "\n",
    "### Harmonize (unique for B stage) ###\n",
    "\n",
    "#GHG_A123_m2_harm\n",
    "df['GHG_A123_m2_harm'] = df['GHG_A123_m2']\n",
    "\n",
    "#GHG_A45_m2_harm\n",
    "df['GHG_A45_m2_harm'] = df['GHG_A45_m2']\n",
    "\n",
    "#GHG_B1234_m2_harm\n",
    "df['GHG_B1234_m2_harm'] = df['GHG_B1234_m2'] * (lca_RSP_harm/df['lca_RSP'])\n",
    "\n",
    "#GHG_B5_m2_harm\n",
    "df['GHG_B5_m2_harm'] = df['GHG_B5_m2'] * (lca_RSP_harm/df['lca_RSP'])\n",
    "\n",
    "#GHG_B67_m2_harm\n",
    "df['GHG_B67_m2_harm'] = df['GHG_B67_m2'] * (lca_RSP_harm/df['lca_RSP'])\n",
    "\n",
    "#GHG_C12_m2_harm\n",
    "df['GHG_C12_m2_harm'] = df['GHG_C12_m2']\n",
    "\n",
    "#GHG_C34_m2_harm\n",
    "df['GHG_C34_m2_harm'] = df['GHG_C34_m2']\n",
    "\n",
    "\n",
    "\n",
    "### Scale harmonized back down to m2a ###\n",
    "\n",
    "#GHG_A123_m2a_harm\n",
    "df.loc[pd.notna(df['GHG_A123_m2_harm']), 'GHG_A123_m2a_harm'] = df['GHG_A123_m2_harm'] / lca_RSP_harm\n",
    "\n",
    "#GHG_A45_m2a_harm\n",
    "df.loc[pd.notna(df['GHG_A45_m2_harm']), 'GHG_A45_m2a_harm'] = df['GHG_A45_m2_harm'] / lca_RSP_harm\n",
    "\n",
    "#GHG_B1234_m2a_harm\n",
    "df.loc[pd.notna(df['GHG_B1234_m2_harm']), 'GHG_B1234_m2a_harm'] = df['GHG_B1234_m2_harm'] / lca_RSP_harm\n",
    "\n",
    "#GHG_B5_m2a_harm\n",
    "df.loc[pd.notna(df['GHG_B5_m2_harm']), 'GHG_B5_m2a_harm'] = df['GHG_B5_m2_harm'] / lca_RSP_harm\n",
    "\n",
    "#GHG_B67_m2a_harm\n",
    "df.loc[pd.notna(df['GHG_B67_m2_harm']), 'GHG_B67_m2a_harm'] = df['GHG_B67_m2_harm'] / lca_RSP_harm\n",
    "\n",
    "#GHG_C12_m2a_harm\n",
    "df.loc[pd.notna(df['GHG_C12_m2_harm']), 'GHG_C12_m2a_harm'] = df['GHG_C12_m2_harm'] / lca_RSP_harm\n",
    "\n",
    "#GHG_C_m2a_harm\n",
    "df.loc[pd.notna(df['GHG_C34_m2_harm']), 'GHG_C34_m2a_harm'] = df['GHG_C34_m2_harm'] / lca_RSP_harm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Harmonize GHG result sums**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If EC per LCS has been harmonized, use them to calculate the harmonized sum of EC\n",
    "# OBS: This code will only provide reliable sums if all three stages are provided/have data.\n",
    "\n",
    "# Calculate GHG_sum_em_m2\n",
    "df['GHG_sum_em_m2'] = df['GHG_A123_m2'].fillna(0) + df['GHG_B1234_m2'].fillna(0) + df['GHG_B5_m2'].fillna(0) + df['GHG_C12_m2'].fillna(0) + df['GHG_C34_m2'].fillna(0)\n",
    "\n",
    "# Calculate GHG_sum_em_m2_harm\n",
    "df['GHG_sum_em_m2_harm'] = df['GHG_A123_m2_harm'].fillna(0) + df['GHG_A45_m2_harm'].fillna(0) + df['GHG_B1234_m2_harm'].fillna(0) + df['GHG_B5_m2_harm'].fillna(0) + df['GHG_C12_m2_harm'].fillna(0) + df['GHG_C34_m2_harm'].fillna(0)\n",
    "\n",
    "# Calculate GHG_sum_em_m2a_harm\n",
    "df['GHG_sum_em_m2a_harm'] =  df['GHG_A123_m2a_harm'].fillna(0) + df['GHG_A45_m2a_harm'].fillna(0) + df['GHG_B1234_m2a_harm'].fillna(0) + df['GHG_B5_m2a_harm'].fillna(0) + df['GHG_C12_m2a_harm'].fillna(0) + df['GHG_C34_m2a_harm'].fillna(0)\n",
    "\n",
    "# If one of the harmonized EC per LCS is NaN, method 1 will not run\n",
    "# Instead method 2 or 3 is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Use the harmonized sum EC and harmonized disaggregated EC to compute and apply a ratio to predict harmonized disaggregated results for cases with no disaggregated results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disaggregate GHG results into A123, A45, B1234, B5, B67, C12 and C34 where needed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GHG results are disaggregated by:\n",
    "<br>1. Identify which cases lack disaggregated GHG results and which don't. Identify the scope_LCM of these cases.\n",
    "<br>2. Use those cases to create a ratio which can predict/disaggregate new cases based on LCS_scope.\n",
    "<br>3. Use the ratio to calculate the GHG results separated into life cycle stages for the cases that need it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Identify cases, scope_LCM and scope_parts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cases without disaggregated results have these LCM scopes:\n",
      "['PMW' 'PC' 'P' 'PCMOD' 'PCO' 'PCMODW' 'PCMRODW' 'PMO' 'PMDW' 'PCOD'\n",
      " 'PMODW' 'PCMROW' 'PCOW' 'PCMO' 'PCODW' 'PM' 'PO' '' 'PCMROD' 'PMOW'\n",
      " 'PCMOW' 'PCM']\n",
      "\n",
      "Cases without disaggregated results have these parts scopes:\n",
      "['GLEIS' 'GLEI' 'GL' '' 'GLIS' 'IS' 'GLSA' 'GLI' 'LI' 'LEI' 'L' 'GLS'\n",
      " 'GLES' 'LE' 'GLE' 'GLEISA' 'GLESA']\n",
      "\n",
      "We can predict cases with these LCM scopes:\n",
      "['PMOW' 'PMW' 'PCMODW' 'PCMDW' 'PCMW' 'PO' 'P' 'PCMRODW' 'PCMOD' 'PCODW'\n",
      " 'PCMROD' 'PCO' 'PCMO' 'PODW' 'PMODW' 'PC' '']\n",
      "\n",
      "We can predict cases with these parts scopes:\n",
      "['GLES' 'GLEIS' 'GLEI' 'GLEISA' 'GLE' 'GL' 'LEISA' 'GLIS' '' 'GLS' 'GLI'\n",
      " 'LEIS']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create new boolean feature to determine whether case has disaggregated results or not\n",
    "df['Bool_1'] = np.nan\n",
    "df['Bool_2'] = np.nan\n",
    "df['Bool_3'] = np.nan\n",
    "\n",
    "### LACK DISAGGREGATION ###\n",
    "# Find cases which lack disaggregated results, return False in the boolean feature\n",
    "df.loc[pd.isnull(df['GHG_A123_m2a_harm']) & pd.isnull(df['GHG_A45_m2a_harm']) & pd.isnull(df['GHG_B1234_m2a_harm']) & pd.isnull(df['GHG_B5_m2a_harm']) & pd.isnull(df['GHG_C12_m2a_harm']) & pd.isnull(df['GHG_C34_m2a_harm']), 'Bool_1'] = 'False'\n",
    "\n",
    "# Create new df with cases that lack disaggregated results\n",
    "df_false = df.loc[df['Bool_1'].isin(['False'])]\n",
    "\n",
    "# Print scopes\n",
    "#print('Cases without disaggregated results have these LCM scopes:')\n",
    "df_false_scopes_LCM = df_false['scope_LCM'].unique()\n",
    "#print(df_false_scopes_LCM)\n",
    "#print()\n",
    "\n",
    "#print('Cases without disaggregated results have these parts scopes:')\n",
    "df_false_scopes_parts = df_false['scope_parts'].unique()\n",
    "#print(df_false_scopes_parts)\n",
    "#print()\n",
    "\n",
    "### HAVE DISAGGREGATION scope_LCM ###\n",
    "# Find cases that have disaggregated results, return True in the boolean feature\n",
    "df.loc[pd.notna(df['GHG_A123_m2a_harm']) | pd.notna(df['GHG_A45_m2a_harm']) | pd.notna(df['GHG_B1234_m2a_harm']) | pd.notna(df['GHG_B5_m2a_harm']) | pd.notna(df['GHG_C12_m2a_harm']) | pd.notna(df['GHG_C34_m2a_harm']), 'Bool_2'] = 'True'\n",
    "\n",
    "# Use it to find the scopes_LCM of the relecant cases\n",
    "df_true_LCM = df.loc[df['Bool_2'].isin(['True'])]\n",
    "#print('We can predict cases with these LCM scopes:')\n",
    "df_true_scopes_LCM = df_true_LCM['scope_LCM'].unique()\n",
    "#print(df_true_scopes_LCM)\n",
    "#print()\n",
    "\n",
    "### HAVE DISAGGREGATION scope_parts ###\n",
    "# Find cases that have disaggregated results, return True in the boolean feature\n",
    "df.loc[pd.notna(df['GHG_A123_m2a_harm']) | pd.notna(df['GHG_A45_m2a_harm']) | pd.notna(df['GHG_B1234_m2a_harm']) | pd.notna(df['GHG_B5_m2a_harm']) | pd.notna(df['GHG_C12_m2a_harm']) | pd.notna(df['GHG_C34_m2a_harm']), 'Bool_3'] = 'True'\n",
    "\n",
    "# Use it to find the scopes_LCM of the relecant cases\n",
    "df_true_parts = df.loc[df['Bool_2'].isin(['True'])]\n",
    "#print('We can predict cases with these parts scopes:')\n",
    "df_true_scopes_parts = df_true_parts['scope_parts'].unique()\n",
    "#print(df_true_scopes_parts)\n",
    "#print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Create ratios for A123, A45, B1234, B5, B67, C12 and C34 for each type of scope_LCM and scope_parts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter cases from df_true using list of true LCM scopes and calculate average ratios\n",
    "list_ratio_1 = []\n",
    "list_ratio_2 = []\n",
    "\n",
    "for scope_LCM in df_true_scopes_LCM:\n",
    "    df_temp = df_true_LCM.loc[df['scope_LCM'].isin([scope_LCM])]\n",
    "\n",
    "    df_temp['ratio_A123']  = (df_temp['GHG_A123_m2a_harm']/df_temp['GHG_sum_em_m2a_harm'])\n",
    "    df_temp['ratio_A45']   = (df_temp['GHG_A45_m2a_harm']/df_temp['GHG_sum_em_m2a_harm'])\n",
    "    df_temp['ratio_B1234'] = (df_temp['GHG_B1234_m2a_harm']/df_temp['GHG_sum_em_m2a_harm'])\n",
    "    df_temp['ratio_B5']    = (df_temp['GHG_B5_m2a_harm']/df_temp['GHG_sum_em_m2a_harm'])\n",
    "    df_temp['ratio_C12'] = (df_temp['GHG_C12_m2a_harm']/df_temp['GHG_sum_em_m2a_harm'])\n",
    "    df_temp['ratio_C34'] = (df_temp['GHG_C34_m2a_harm']/df_temp['GHG_sum_em_m2a_harm'])\n",
    "    \n",
    "    df_temp = df_temp[['ratio_A123','ratio_A45','ratio_B1234','ratio_B5','ratio_C12','ratio_C34']].mean()\n",
    "\n",
    "    list_ratio_1.append([str(scope_LCM),df_temp[['ratio_A123','ratio_A45','ratio_B1234','ratio_B5','ratio_C12','ratio_C34']]])\n",
    "    \n",
    "for scope_parts in df_true_scopes_parts:\n",
    "    df_temp = df_true_parts.loc[df['scope_parts'].isin([scope_parts])]\n",
    "\n",
    "    df_temp['ratio_A123']  = (df_temp['GHG_A123_m2a_harm']/df_temp['GHG_sum_em_m2a_harm'])\n",
    "    df_temp['ratio_A45']   = (df_temp['GHG_A45_m2a_harm']/df_temp['GHG_sum_em_m2a_harm'])\n",
    "    df_temp['ratio_B1234'] = (df_temp['GHG_B1234_m2a_harm']/df_temp['GHG_sum_em_m2a_harm'])\n",
    "    df_temp['ratio_B5']    = (df_temp['GHG_B5_m2a_harm']/df_temp['GHG_sum_em_m2a_harm'])\n",
    "    df_temp['ratio_C12'] = (df_temp['GHG_C12_m2a_harm']/df_temp['GHG_sum_em_m2a_harm'])\n",
    "    df_temp['ratio_C34'] = (df_temp['GHG_C34_m2a_harm']/df_temp['GHG_sum_em_m2a_harm'])\n",
    "    \n",
    "    df_temp = df_temp[['ratio_A123','ratio_A45','ratio_B1234','ratio_B5','ratio_C12','ratio_C34']].mean()\n",
    "\n",
    "    list_ratio_2.append([str(scope_parts),df_temp[['ratio_A123','ratio_A45','ratio_B1234','ratio_B5','ratio_C12','ratio_C34']]])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Apply ratios and calculate disaggregated results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra code to convert CSTB data with lca_RSP of 50 to harm data\n",
    "df.loc[(df['admin_data_partner'] == 'CSTB') & (df['lca_RSP'] == 50),'GHG_sum_em_m2a_harm'] = df['GHG_sum_em_m2a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply ratios for LCM to GHG_A_m2a, GHG_B_em_m2a and GHG_C_m2a where bool is false and the scopes match\n",
    "\n",
    "for scope_LCM in df_false_scopes_LCM:\n",
    "    for i in range(0,len(list_ratio_1)):\n",
    "        \n",
    "        scope = list_ratio_1[i][0]\n",
    "        \n",
    "        #Compute A123\n",
    "        ratio = list_ratio_1[i][1]['ratio_A123']\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_LCM'] == scope), 'GHG_A123_m2a_harm_LCM'] = df['GHG_sum_em_m2a_harm']*ratio\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_LCM'] == scope), 'ratio_A123_LCM'] = ratio\n",
    "            \n",
    "        #Compute A45\n",
    "        ratio = list_ratio_1[i][1]['ratio_A45']\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_LCM'] == scope), 'GHG_A45_m2a_harm_LCM'] = df['GHG_sum_em_m2a_harm']*ratio\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_LCM'] == scope), 'ratio_A45_LCM'] = ratio\n",
    "        \n",
    "        #Compute B1234\n",
    "        ratio = list_ratio_1[i][1]['ratio_B1234']\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_LCM'] == scope), 'GHG_B1234_m2a_harm_LCM'] = df['GHG_sum_em_m2a_harm']*ratio\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_LCM'] == scope), 'ratio_B1234_LCM'] = ratio\n",
    "        \n",
    "        #Compute B5\n",
    "        ratio = list_ratio_1[i][1]['ratio_B5']\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_LCM'] == scope), 'GHG_B5_m2a_harm_LCM'] = df['GHG_sum_em_m2a_harm']*ratio\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_LCM'] == scope), 'ratio_B5_LCM'] = ratio\n",
    "        \n",
    "        #Compute C12\n",
    "        ratio = list_ratio_1[i][1]['ratio_C12']\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_LCM'] == scope), 'GHG_C12_m2a_harm_LCM'] = df['GHG_sum_em_m2a_harm']*ratio\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_LCM'] == scope), 'ratio_C12_LCM'] = ratio\n",
    "        \n",
    "        #Compute C34\n",
    "        ratio = list_ratio_1[i][1]['ratio_C34']\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_LCM'] == scope), 'GHG_C34_m2a_harm_LCM'] = df['GHG_sum_em_m2a_harm']*ratio\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_LCM'] == scope), 'ratio_C34_LCM'] = ratio\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply ratios for parts to GHG_A_m2a, GHG_B_em_m2a and GHG_C_m2a where bool is false and the scopes match\n",
    "\n",
    "for scope_parts in df_false_scopes_parts:\n",
    "    for i in range(0,len(list_ratio_2)):\n",
    "        \n",
    "        scope = list_ratio_2[i][0]\n",
    "        \n",
    "        #Compute A123\n",
    "        ratio = list_ratio_2[i][1]['ratio_A123']\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_parts'] == scope), 'GHG_A123_m2a_harm_parts'] = df['GHG_sum_em_m2a_harm']*ratio\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_parts'] == scope), 'ratio_A123_parts'] = ratio\n",
    "        \n",
    "        #Compute A45\n",
    "        ratio = list_ratio_2[i][1]['ratio_A45']\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_parts'] == scope), 'GHG_A45_m2a_harm_parts'] = df['GHG_sum_em_m2a_harm']*ratio\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_parts'] == scope), 'ratio_A45_parts'] = ratio\n",
    "        \n",
    "        #Compute B1234\n",
    "        ratio = list_ratio_2[i][1]['ratio_B1234']\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_parts'] == scope), 'GHG_B1234_m2a_harm_parts'] = df['GHG_sum_em_m2a_harm']*ratio\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_parts'] == scope), 'ratio_B1234_parts'] = ratio\n",
    "        \n",
    "        #Compute B5\n",
    "        ratio = list_ratio_2[i][1]['ratio_B5']\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_parts'] == scope), 'GHG_B5_m2a_harm_parts'] = df['GHG_sum_em_m2a_harm']*ratio\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_parts'] == scope), 'ratio_B5_parts'] = ratio\n",
    "        \n",
    "        #Compute C12\n",
    "        ratio = list_ratio_2[i][1]['ratio_C12']\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_parts'] == scope), 'GHG_C12_m2a_harm_parts'] = df['GHG_sum_em_m2a_harm']*ratio\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_parts'] == scope), 'ratio_C12_parts'] = ratio\n",
    "        \n",
    "        #Compute C34\n",
    "        ratio = list_ratio_2[i][1]['ratio_C34']\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_parts'] == scope), 'GHG_C34_m2a_harm_parts'] = df['GHG_sum_em_m2a_harm']*ratio\n",
    "        df.loc[(df['Bool_1'] == 'False') & (df['scope_parts'] == scope), 'ratio_C34_parts'] = ratio\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Recreate and store ratios for data that already has disaggregated results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These ratios are not applied and are only used for comparison and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A123\n",
    "df.loc[pd.isnull(df['ratio_A123_LCM']),'ratio_A123_LCM'] = df['GHG_A123_m2a_harm']/df['GHG_sum_em_m2a_harm']\n",
    "#A45\n",
    "df.loc[pd.isnull(df['ratio_A45_LCM']),'ratio_A45_LCM'] = df['GHG_A45_m2a_harm']/df['GHG_sum_em_m2a_harm']\n",
    "#B1234\n",
    "df.loc[pd.isnull(df['ratio_B1234_LCM']),'ratio_B1234_LCM'] = df['GHG_B1234_m2a_harm']/df['GHG_sum_em_m2a_harm']\n",
    "#B5\n",
    "df.loc[pd.isnull(df['ratio_B5_LCM']),'ratio_B5_LCM'] = df['GHG_B5_m2a_harm']/df['GHG_sum_em_m2a_harm']\n",
    "#C12\n",
    "df.loc[pd.isnull(df['ratio_C12_LCM']),'ratio_C12_LCM'] = df['GHG_C12_m2a_harm']/df['GHG_sum_em_m2a_harm']\n",
    "#C34\n",
    "df.loc[pd.isnull(df['ratio_C34_LCM']),'ratio_C34_LCM'] = df['GHG_C34_m2a_harm']/df['GHG_sum_em_m2a_harm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A123\n",
    "df.loc[pd.isnull(df['ratio_A123_parts']),'ratio_A123_parts'] = df['GHG_A123_m2a_harm']/df['GHG_sum_em_m2a_harm']\n",
    "#A45\n",
    "df.loc[pd.isnull(df['ratio_A45_parts']),'ratio_A45_parts'] = df['GHG_A45_m2a_harm']/df['GHG_sum_em_m2a_harm']\n",
    "#B1234\n",
    "df.loc[pd.isnull(df['ratio_B1234_parts']),'ratio_B1234_parts'] = df['GHG_B1234_m2a_harm']/df['GHG_sum_em_m2a_harm']\n",
    "#B5\n",
    "df.loc[pd.isnull(df['ratio_B5_parts']),'ratio_B5_parts'] = df['GHG_B5_m2a_harm']/df['GHG_sum_em_m2a_harm']\n",
    "#C12\n",
    "df.loc[pd.isnull(df['ratio_C12_parts']),'ratio_C12_parts'] = df['GHG_C12_m2a_harm']/df['GHG_sum_em_m2a_harm']\n",
    "#C34\n",
    "df.loc[pd.isnull(df['ratio_C34_parts']),'ratio_C34_parts'] = df['GHG_C34_m2a_harm']/df['GHG_sum_em_m2a_harm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fix Residential cases in bldg_use_type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace wrong entries\n",
    "df.bldg_use_type.replace('Residential ','Residential',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace 0 with NaN in all columns (except 'bldg_floors_bg') after feature engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'bldg_floors_bg' is allowed to have 0, the rest are changed to NaN\n",
    "\n",
    "#Create list of columns without 'bldg_floors_bg'\n",
    "col_list = list(df.drop('bldg_floors_bg',axis=1).columns)\n",
    "\n",
    "#Loop over list of columns and replace 0 with NaN\n",
    "for col in col_list:\n",
    "    df[col].replace(to_replace=[0,\"0\"], value=np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correct datatypes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of features to correct\n",
    "feature_list = [\n",
    "    \"bldg_floors_ag\",\n",
    "    \"bldg_floors_ag\",\n",
    "    \"bldg_floors_bg\",\n",
    "    \"mass_ceramics\",\n",
    "    \"mass_concrete_reinforced\",\n",
    "    \"mass_glass\",\n",
    "    \"mass_metals\",\n",
    "    \"mass_wood\",\n",
    "    \"eurostat_biomass_based_materials\",\n",
    "    \"lca_RSP\"\n",
    "]\n",
    "\n",
    "#Change data type of features in list to numeric (float)\n",
    "df[feature_list] = df[feature_list].apply(pd.to_numeric,errors='coerce')\n",
    "\n",
    "#Data that can't be transformed to float will be set to NaN given the \"errors='coerce'\" argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bldg_floors_ag                      float64\n",
       "bldg_floors_ag                      float64\n",
       "bldg_floors_bg                      float64\n",
       "mass_ceramics                       float64\n",
       "mass_concrete_reinforced            float64\n",
       "mass_glass                          float64\n",
       "mass_metals                         float64\n",
       "mass_wood                           float64\n",
       "eurostat_biomass_based_materials    float64\n",
       "lca_RSP                             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[feature_list].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataframe for export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T21:33:57.529260Z",
     "start_time": "2021-06-05T21:33:57.514300Z"
    }
   },
   "outputs": [],
   "source": [
    "#Reorder columns in dataframe using double brackets (columns that aren't called are dropped):\n",
    "\n",
    "df = df[[\n",
    "    'site_country_code',\n",
    "    'admin_project_code',\n",
    "    'admin_data_partner',\n",
    "    'admin_project_contact',\n",
    "    'bldg_use_type',\n",
    "    'bldg_use_subtype',\n",
    "    'bldg_project_status',\n",
    "    'site_country',\n",
    "    'bldg_year_permit',\n",
    "    'bldg_year_complete',\n",
    "    'bldg_year_complete_interval',\n",
    "    'bldg_QTO_type',\n",
    "    'bldg_area_definition',\n",
    "    'bldg_area_gfa','bldg_area_hfa',\n",
    "    'bldg_area_interval',\n",
    "    'bldg_users_total',\n",
    "    'bldg_floors_ag',\n",
    "    'bldg_floors_bg',\n",
    "    'bldg_struct_type',\n",
    "    'bldg_roof_type',\n",
    "    'bldg_energy_class_general',\n",
    "    'bldg_energy_class_country',\n",
    "    'bldg_certification',\n",
    "    \n",
    "    'inv_energy_consumption',\n",
    "    'inv_mat_mass_total',\n",
    "    'inv_mat_mass_total_m2',\n",
    "    'inv_mat_mass_total_capita',\n",
    "    'inv_mat_mass_sum_top_5',\n",
    "    'inv_mat_mass_ratio',\n",
    "    'inv_mat_1_type',\n",
    "    'inv_mat_1_mass',\n",
    "    'inv_mat_2_type',\n",
    "    'inv_mat_2_mass',\n",
    "    'inv_mat_3_type',\n",
    "    'inv_mat_3_mass',\n",
    "    'inv_mat_4_type',\n",
    "    'inv_mat_4_mass',\n",
    "    'inv_mat_5_type',\n",
    "    'inv_mat_5_mass',\n",
    "    \n",
    "    'mass_aluminium',\n",
    "    'mass_bamboo',\n",
    "    'mass_brass_copper',\n",
    "    'mass_cement_mortar',\n",
    "    'mass_ceramics',\n",
    "    'mass_concrete_reinforced',\n",
    "    'mass_concrete_wo_reinforcement',\n",
    "    'mass_earth',\n",
    "    'mass_EPS_XPS',\n",
    "    'mass_fungi',\n",
    "    'mass_glass',\n",
    "    'mass_metals',\n",
    "    'mass_plastics',\n",
    "    'mass_steel_reinforcement',\n",
    "    'mass_stone',\n",
    "    'mass_stone_wool',\n",
    "    'mass_straw_hemp',\n",
    "    'mass_wood',\n",
    "    'mass_other',\n",
    "    \n",
    "    'eurostat_metal_materials',\n",
    "    'eurostat_non-metallic_minerals',\n",
    "    'eurostat_fossil_energy_materials',\n",
    "    'eurostat_biomass_based_materials',\n",
    "    \n",
    "    'lca_RSP',\n",
    "    'lca_software',\n",
    "    'lca_database',\n",
    "    'lca_scenarios_decarbonisation',\n",
    "    \n",
    "    'scope_parts',\n",
    "    'scope_LCS',\n",
    "    'scope_LCM',    \n",
    "    \n",
    "    'scope_parts_1_ground',\n",
    "    'scope_parts_2_structure',\n",
    "    'scope_parts_3_secondary',\n",
    "    'scope_parts_4_finishes',\n",
    "    'scope_parts_5_mechanical',\n",
    "    'scope_parts_6_electrical',\n",
    "    'scope_parts_6+_renewables',\n",
    "    'scope_parts_7_facilities',\n",
    "    'scope_parts_8_fittings',\n",
    "    \n",
    "    'scope_LCS_A123',\n",
    "    'scope_LCS_A4',\n",
    "    'scope_LCS_A5',\n",
    "    'scope_LCS_B1',\n",
    "    'scope_LCS_B2',\n",
    "    'scope_LCS_B3',\n",
    "    'scope_LCS_B4',\n",
    "    'scope_LCS_B5',\n",
    "    'scope_LCS_B6',\n",
    "    'scope_LCS_B7',\n",
    "    'scope_LCS_B8',\n",
    "    'scope_LCS_C1',\n",
    "    'scope_LCS_C2',\n",
    "    'scope_LCS_C3',\n",
    "    'scope_LCS_C4',\n",
    "    'scope_LCS_D',\n",
    "    'scope_handling_D',\n",
    "    \n",
    "    'GHG_sum_em',\n",
    "    'GHG_sum_em_m2a',\n",
    "    'GHG_sum_em_capita_a',\n",
    "    \n",
    "    'GHG_A_m2a',\n",
    "    'GHG_B_em_m2a',\n",
    "    'GHG_B_op_m2a',\n",
    "    'GHG_C_m2a',\n",
    "        \n",
    "    'GHG_A_capita_a',\n",
    "    'GHG_B_em_capita_a',\n",
    "    'GHG_B_op_capita_a',\n",
    "    'GHG_C_capita_a',\n",
    "    \n",
    "#    'GHG_A1',\n",
    "#    'GHG_A2',\n",
    "#    'GHG_A3',\n",
    "#    'GHG_A4',\n",
    "#    'GHG_A5',\n",
    "#    'GHG_B1',\n",
    "#    'GHG_B2',\n",
    "#    'GHG_B3',\n",
    "#    'GHG_B4',\n",
    "#    'GHG_B5',\n",
    "#    'GHG_B6',\n",
    "#    'GHG_B7',\n",
    "#    'GHG_C1',\n",
    "#    'GHG_C2',\n",
    "#    'GHG_C3',\n",
    "#    'GHG_C4',\n",
    "#    'GHG_D',\n",
    "    \n",
    "    'GHG_A1_m2a',\n",
    "    'GHG_A2_m2a',\n",
    "    'GHG_A3_m2a',\n",
    "    'GHG_A4_m2a',\n",
    "    'GHG_A5_m2a',\n",
    "    'GHG_B1_m2a',\n",
    "    'GHG_B2_m2a',\n",
    "    'GHG_B3_m2a',\n",
    "    'GHG_B4_m2a',\n",
    "    'GHG_B6_m2a',\n",
    "    'GHG_B7_m2a',\n",
    "    'GHG_C1_m2a',\n",
    "    'GHG_C2_m2a',\n",
    "    'GHG_C3_m2a',\n",
    "    'GHG_C4_m2a',\n",
    "    \n",
    "#    'GHG_A123',\n",
    "#    'GHG_A45',\n",
    "#    'GHG_B1234',\n",
    "#    'GHG_B67',\n",
    "#    'GHG_C12',\n",
    "#    'GHG_C34',\n",
    "#    'GHG_C34_D',\n",
    "    \n",
    "    'GHG_A123_m2a', #Normal results per m2a\n",
    "    'GHG_A45_m2a',\n",
    "    'GHG_B1234_m2a',\n",
    "    'GHG_B5_m2a',\n",
    "    'GHG_B67_m2a',\n",
    "    'GHG_C12_m2a',\n",
    "    'GHG_C34_m2a',\n",
    "    'GHG_D_m2a',\n",
    "#    'GHG_C34_D_m2a',\n",
    "    \n",
    "    'GHG_A123_m2a_APEN', #APEN harmonized results per m2a\n",
    "    'GHG_A45_m2a_APEN',\n",
    "    'GHG_B1234_m2a_APEN',\n",
    "    'GHG_B5_m2a_APEN',\n",
    "    'GHG_B67_m2a_APEN',\n",
    "    'GHG_C12_m2a_APEN',\n",
    "    'GHG_C34_m2a_APEN',\n",
    "    'GHG_D_m2a_APEN',\n",
    "    'GHG_sum_em_m2a_APEN',\n",
    "    'GHG_sum_op_m2a_APEN',\n",
    "    \n",
    "    'GHG_A123_m2a_harm', #Harmonized results per m2a\n",
    "    'GHG_A45_m2a_harm',\n",
    "    'GHG_B1234_m2a_harm',\n",
    "    'GHG_B5_m2a_harm',\n",
    "    'GHG_B67_m2a_harm',    \n",
    "    'GHG_C12_m2a_harm',\n",
    "    'GHG_C34_m2a_harm',\n",
    "    'GHG_sum_em_m2a_harm',\n",
    "    \n",
    "#    'GHG_A123_m2_harm', #Harmonized results per m2 (no a) (disabled for now due to simplicity of recreating it on the fly)\n",
    "#    'GHG_A45_m2_harm',\n",
    "#    'GHG_B1234_m2_harm',\n",
    "#    'GHG_B5_m2_harm',\n",
    "#    'GHG_C12_m2_harm',\n",
    "#    'GHG_C34_m2_harm',\n",
    "#    'GHG_sum_em_m2_harm',\n",
    "    \n",
    "    'GHG_A123_m2a_harm_LCM', #Harmonized results per m2a with LCM ratio disaggregation applied where needed\n",
    "    'GHG_A45_m2a_harm_LCM',\n",
    "    'GHG_B1234_m2a_harm_LCM',\n",
    "    'GHG_B5_m2a_harm_LCM',\n",
    "    'GHG_C12_m2a_harm_LCM',\n",
    "    'GHG_C34_m2a_harm_LCM',\n",
    "    \n",
    "    'GHG_P1_sum_m2a',\n",
    "    'GHG_P1_A123_m2a',\n",
    "    'GHG_P1_A45_m2a',\n",
    "    'GHG_P1_B1234_m2a',\n",
    "    'GHG_P1_B5_m2a',\n",
    "    'GHG_P1_C12_m2a',\n",
    "    'GHG_P1_C34_m2a',\n",
    "    'GHG_P1_D_m2a',\n",
    "    \n",
    "    'GHG_P2_sum_m2a',\n",
    "    'GHG_P2_A123_m2a',\n",
    "    'GHG_P2_A45_m2a',\n",
    "    'GHG_P2_B1234_m2a',\n",
    "    'GHG_P2_B5_m2a',\n",
    "    'GHG_P2_C12_m2a',\n",
    "    'GHG_P2_C34_m2a',\n",
    "    'GHG_P2_D_m2a',\n",
    "    \n",
    "    'GHG_P34_sum_m2a',\n",
    "    'GHG_P34_A123_m2a',\n",
    "    'GHG_P34_A45_m2a',\n",
    "    'GHG_P34_B1234_m2a',\n",
    "    'GHG_P34_B5_m2a',\n",
    "    'GHG_P34_C12_m2a',\n",
    "    'GHG_P34_C34_m2a',\n",
    "    'GHG_P34_D_m2a',\n",
    "    \n",
    "    'GHG_P4_sum_m2a',\n",
    "    'GHG_P4_A123_m2a',\n",
    "    'GHG_P4_A45_m2a',\n",
    "    'GHG_P4_B1234_m2a',\n",
    "    'GHG_P4_B5_m2a',\n",
    "    'GHG_P4_C12_m2a',\n",
    "    'GHG_P4_C34_m2a',\n",
    "    'GHG_P4_D_m2a',\n",
    "    \n",
    "    'GHG_P56_sum_m2a',\n",
    "    'GHG_P56_A123_m2a',\n",
    "    'GHG_P56_A45_m2a',\n",
    "    'GHG_P56_B1234_m2a',\n",
    "    'GHG_P56_B5_m2a',\n",
    "    'GHG_P56_C12_m2a',\n",
    "    'GHG_P56_C34_m2a',\n",
    "    'GHG_P56_D_m2a',\n",
    "    \n",
    "    'GHG_P78_sum_m2a',\n",
    "    'GHG_P78_A123_m2a',\n",
    "    'GHG_P78_A45_m2a',\n",
    "    'GHG_P78_B1234_m2a',\n",
    "    'GHG_P78_B5_m2a',\n",
    "    'GHG_P78_C12_m2a',\n",
    "    'GHG_P78_C34_m2a',\n",
    "    'GHG_P78_D_m2a',\n",
    "    \n",
    "    'GHG_sum_em_m2pertonGHG_a',\n",
    "    'GHG_sum_em_m2pertonGHG',\n",
    "    'GHG_sum_op_m2pertonGHG_a',\n",
    "    'GHG_sum_op_m2pertonGHG',\n",
    "    'GHG_sum_em_cappertonGHG_a',\n",
    "    'GHG_sum_em_cappertonGHG',\n",
    "    'GHG_sum_op_cappertonGHG_a',\n",
    "    'GHG_sum_op_cappertonGHG',\n",
    "\n",
    "    'ratio_A123_LCM',\n",
    "    'ratio_A45_LCM',\n",
    "    'ratio_B1234_LCM',\n",
    "    'ratio_B5_LCM',\n",
    "    'ratio_C12_LCM',\n",
    "    'ratio_C34_LCM',\n",
    "    \n",
    "    'ratio_A123_parts',\n",
    "    'ratio_A45_parts',\n",
    "    'ratio_B1234_parts',\n",
    "    'ratio_B5_parts',\n",
    "    'ratio_C12_parts',\n",
    "    'ratio_C34_parts' \n",
    "    \n",
    "]]\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T21:33:57.544220Z",
     "start_time": "2021-06-05T21:33:57.531255Z"
    }
   },
   "outputs": [],
   "source": [
    "#print(df.shape)\n",
    "#print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T21:33:57.652979Z",
     "start_time": "2021-06-05T21:33:57.546215Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create csv\n",
    "filename = '00_data/3_data_feature_engineered/EU-ECB_dataset_feature_engineered.csv'\n",
    "df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data has been feature engineered and ready for analysis.\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "886px",
    "left": "1728.71px",
    "right": "20px",
    "top": "127.956px",
    "width": "649px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
